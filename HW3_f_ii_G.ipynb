{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test error estimates : \n",
      "    Estimated Test Error\n",
      "1               11.6484\n",
      "2                12.967\n",
      "3               14.6154\n",
      "4               10.2198\n",
      "5               14.3956\n",
      "6               11.5385\n",
      "7               15.9341\n",
      "8               14.6154\n",
      "9               18.7912\n",
      "10              24.7253\n",
      "11              18.9011\n",
      "12              15.8242\n",
      "13              20.2198\n",
      "14              23.2967\n",
      "15              17.5824\n",
      "16              21.4286\n",
      "17              17.4725\n",
      "18               21.978\n",
      "19               26.044\n",
      "20              24.6154\n",
      "The l split selected that minimizes the test error estimate for this multiclass classification is : \n",
      " 4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "df1 = pd.read_csv('bending1\\\\training\\\\dataset3.csv')\n",
    "df2 = pd.read_csv('bending1\\\\training\\\\dataset4.csv')\n",
    "df3 = pd.read_csv('bending1\\\\training\\\\dataset5.csv')\n",
    "df4 = pd.read_csv('bending1\\\\training\\\\dataset6.csv')\n",
    "df5 = pd.read_csv('bending1\\\\training\\\\dataset7.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df6 = pd.read_csv('bending2\\\\training\\\\dataset3.csv')\n",
    "df7 = pd.read_csv('bending2\\\\training\\\\dataset4.csv')\n",
    "df8 = pd.read_csv('bending2\\\\training\\\\dataset5.csv')\n",
    "df9 = pd.read_csv('bending2\\\\training\\\\dataset6.csv')\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "df10 = pd.read_csv('cycling\\\\training\\\\dataset4.csv')\n",
    "df11 = pd.read_csv('cycling\\\\training\\\\dataset5.csv')\n",
    "df12 = pd.read_csv('cycling\\\\training\\\\dataset6.csv')\n",
    "df13 = pd.read_csv('cycling\\\\training\\\\dataset7.csv')\n",
    "df14 = pd.read_csv('cycling\\\\training\\\\dataset8.csv')\n",
    "df15 = pd.read_csv('cycling\\\\training\\\\dataset9.csv')\n",
    "df16 = pd.read_csv('cycling\\\\training\\\\dataset10.csv')\n",
    "df17 = pd.read_csv('cycling\\\\training\\\\dataset11.csv')\n",
    "df18 = pd.read_csv('cycling\\\\training\\\\dataset12.csv')\n",
    "df19 = pd.read_csv('cycling\\\\training\\\\dataset13.csv')\n",
    "df20 = pd.read_csv('cycling\\\\training\\\\dataset14.csv')\n",
    "df21 = pd.read_csv('cycling\\\\training\\\\dataset15.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df22 = pd.read_csv('lying\\\\training\\\\dataset4.csv')\n",
    "df23 = pd.read_csv('lying\\\\training\\\\dataset5.csv')\n",
    "df24 = pd.read_csv('lying\\\\training\\\\dataset6.csv')\n",
    "df25 = pd.read_csv('lying\\\\training\\\\dataset7.csv')\n",
    "df26 = pd.read_csv('lying\\\\training\\\\dataset8.csv')\n",
    "df27 = pd.read_csv('lying\\\\training\\\\dataset9.csv')\n",
    "df28 = pd.read_csv('lying\\\\training\\\\dataset10.csv')\n",
    "df29 = pd.read_csv('lying\\\\training\\\\dataset11.csv')\n",
    "df30 = pd.read_csv('lying\\\\training\\\\dataset12.csv')\n",
    "df31 = pd.read_csv('lying\\\\training\\\\dataset13.csv')\n",
    "df32 = pd.read_csv('lying\\\\training\\\\dataset14.csv')\n",
    "df33 = pd.read_csv('lying\\\\training\\\\dataset15.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "df34 = pd.read_csv('sitting\\\\training\\\\dataset4.csv')\n",
    "df35 = pd.read_csv('sitting\\\\training\\\\dataset5.csv')\n",
    "df36 = pd.read_csv('sitting\\\\training\\\\dataset6.csv')\n",
    "df37 = pd.read_csv('sitting\\\\training\\\\dataset7.csv')\n",
    "df38 = pd.read_csv('sitting\\\\training\\\\dataset8.csv')\n",
    "df39 = pd.read_csv('sitting\\\\training\\\\dataset9.csv')\n",
    "df40 = pd.read_csv('sitting\\\\training\\\\dataset10.csv')\n",
    "df41 = pd.read_csv('sitting\\\\training\\\\dataset11.csv')\n",
    "df42 = pd.read_csv('sitting\\\\training\\\\dataset12.csv')\n",
    "df43 = pd.read_csv('sitting\\\\training\\\\dataset13.csv')\n",
    "df44 = pd.read_csv('sitting\\\\training\\\\dataset14.csv')\n",
    "df45 = pd.read_csv('sitting\\\\training\\\\dataset15.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df46 = pd.read_csv('standing\\\\training\\\\dataset4.csv')\n",
    "df47 = pd.read_csv('standing\\\\training\\\\dataset5.csv')\n",
    "df48 = pd.read_csv('standing\\\\training\\\\dataset6.csv')\n",
    "df49 = pd.read_csv('standing\\\\training\\\\dataset7.csv')\n",
    "df50 = pd.read_csv('standing\\\\training\\\\dataset8.csv')\n",
    "df51 = pd.read_csv('standing\\\\training\\\\dataset9.csv')\n",
    "df52 = pd.read_csv('standing\\\\training\\\\dataset10.csv')\n",
    "df53 = pd.read_csv('standing\\\\training\\\\dataset11.csv')\n",
    "df54 = pd.read_csv('standing\\\\training\\\\dataset12.csv')\n",
    "df55 = pd.read_csv('standing\\\\training\\\\dataset13.csv')\n",
    "df56 = pd.read_csv('standing\\\\training\\\\dataset14.csv')\n",
    "df57 = pd.read_csv('standing\\\\training\\\\dataset15.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df58 = pd.read_csv('walking\\\\training\\\\dataset4.csv')\n",
    "df59 = pd.read_csv('walking\\\\training\\\\dataset5.csv')\n",
    "df60 = pd.read_csv('walking\\\\training\\\\dataset6.csv')\n",
    "df61 = pd.read_csv('walking\\\\training\\\\dataset7.csv')\n",
    "df62 = pd.read_csv('walking\\\\training\\\\dataset8.csv')\n",
    "df63 = pd.read_csv('walking\\\\training\\\\dataset9.csv')\n",
    "df64 = pd.read_csv('walking\\\\training\\\\dataset10.csv')\n",
    "df65 = pd.read_csv('walking\\\\training\\\\dataset11.csv')\n",
    "df66 = pd.read_csv('walking\\\\training\\\\dataset12.csv')\n",
    "df67 = pd.read_csv('walking\\\\training\\\\dataset13.csv')\n",
    "df68 = pd.read_csv('walking\\\\training\\\\dataset14.csv')\n",
    "df69 = pd.read_csv('walking\\\\training\\\\dataset15.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df1 = df1.drop(df1.columns[0],axis=1)\n",
    "df2 = df2.drop(df2.columns[0],axis=1)\n",
    "df3 = df3.drop(df3.columns[0],axis=1)\n",
    "df4 = df4.drop(df4.columns[0],axis=1)\n",
    "df5 = df5.drop(df5.columns[0],axis=1)\n",
    "df6 = df6.drop(df6.columns[0],axis=1)\n",
    "df7 = df7.drop(df7.columns[0],axis=1)\n",
    "df8 = df8.drop(df8.columns[0],axis=1)\n",
    "df9 = df9.drop(df9.columns[0],axis=1)\n",
    "df10 = df10.drop(df10.columns[0],axis=1)\n",
    "df11 = df11.drop(df11.columns[0],axis=1)\n",
    "df12 = df12.drop(df12.columns[0],axis=1)\n",
    "df13 = df13.drop(df13.columns[0],axis=1)\n",
    "df14 = df14.drop(df14.columns[0],axis=1)\n",
    "df15 = df15.drop(df15.columns[0],axis=1)\n",
    "df16 = df16.drop(df16.columns[0],axis=1)\n",
    "df17 = df17.drop(df17.columns[0],axis=1)\n",
    "df18 = df18.drop(df18.columns[0],axis=1)\n",
    "df19 = df19.drop(df19.columns[0],axis=1)\n",
    "df20 = df20.drop(df20.columns[0],axis=1)\n",
    "df21 = df21.drop(df21.columns[0],axis=1)\n",
    "df22 = df22.drop(df22.columns[0],axis=1)\n",
    "df23 = df23.drop(df23.columns[0],axis=1)\n",
    "df24 = df24.drop(df24.columns[0],axis=1)\n",
    "df25 = df25.drop(df25.columns[0],axis=1)\n",
    "df26 = df26.drop(df26.columns[0],axis=1)\n",
    "df27 = df27.drop(df27.columns[0],axis=1)\n",
    "df28 = df28.drop(df28.columns[0],axis=1)\n",
    "df29 = df29.drop(df29.columns[0],axis=1)\n",
    "df30 = df30.drop(df30.columns[0],axis=1)\n",
    "df31 = df31.drop(df31.columns[0],axis=1)\n",
    "df32 = df32.drop(df32.columns[0],axis=1)\n",
    "df33 = df33.drop(df33.columns[0],axis=1)\n",
    "df34 = df34.drop(df34.columns[0],axis=1)\n",
    "df35 = df35.drop(df35.columns[0],axis=1)\n",
    "df36 = df36.drop(df36.columns[0],axis=1)\n",
    "df37 = df37.drop(df37.columns[0],axis=1)\n",
    "df38 = df38.drop(df38.columns[0],axis=1)\n",
    "df39 = df39.drop(df39.columns[0],axis=1)\n",
    "df40 = df40.drop(df40.columns[0],axis=1)\n",
    "df41 = df41.drop(df41.columns[0],axis=1)\n",
    "df42 = df42.drop(df42.columns[0],axis=1)\n",
    "df43 = df43.drop(df43.columns[0],axis=1)\n",
    "df44 = df44.drop(df44.columns[0],axis=1)\n",
    "df45 = df45.drop(df45.columns[0],axis=1)\n",
    "df46 = df46.drop(df46.columns[0],axis=1)\n",
    "df47 = df47.drop(df47.columns[0],axis=1)\n",
    "df48 = df48.drop(df48.columns[0],axis=1)\n",
    "df49 = df49.drop(df49.columns[0],axis=1)\n",
    "df50 = df50.drop(df50.columns[0],axis=1)\n",
    "df51 = df51.drop(df51.columns[0],axis=1)\n",
    "df52 = df52.drop(df52.columns[0],axis=1)\n",
    "df53 = df53.drop(df53.columns[0],axis=1)\n",
    "df54 = df54.drop(df54.columns[0],axis=1)\n",
    "df55 = df55.drop(df55.columns[0],axis=1)\n",
    "df56 = df56.drop(df56.columns[0],axis=1)\n",
    "df57 = df57.drop(df57.columns[0],axis=1)\n",
    "df58 = df58.drop(df58.columns[0],axis=1)\n",
    "df59 = df59.drop(df59.columns[0],axis=1)\n",
    "df60 = df60.drop(df60.columns[0],axis=1)\n",
    "df61 = df61.drop(df61.columns[0],axis=1)\n",
    "df62 = df62.drop(df62.columns[0],axis=1)\n",
    "df63 = df63.drop(df63.columns[0],axis=1)\n",
    "df64 = df64.drop(df64.columns[0],axis=1)\n",
    "df65 = df65.drop(df65.columns[0],axis=1)\n",
    "df66 = df66.drop(df66.columns[0],axis=1)\n",
    "df67 = df67.drop(df67.columns[0],axis=1)\n",
    "df68 = df68.drop(df68.columns[0],axis=1)\n",
    "df69 = df69.drop(df69.columns[0],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_list = [df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16,df17,df18,df19,df20,df21,df22,df23,df24,df25,df26,df27,df28,df29,df30,df31,df32,df33,df34,df35,df36,df37,df38,df39,df40,df41,df42,df43,df44,df45,df46,df47,df48,df49,df50,df51,df52,df53,df54,df55,df56,df57,df58,df59,df60,df61,df62,df63,df64,df65,df66,df67,df68,df69]\n",
    "\n",
    "out =     [0,  0,  0,  0,  0,  0,  0,  0,  0,  1,   1,    1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   2,   2,   2,   2,   2,  2,     2,    2,   2,   2,   2,  2,  3,   3,    3,    3,   3,  3,   3,   3,   3,   3,   3,   3,   4,    4,   4,  4,    4,   4,   4,   4,  4,   4,   4,   4,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5]\n",
    "\n",
    "# 69 datasets, each dataset will me split, features extracted, and instantiated in that same index in a corresponding manner\n",
    "# thus out has 69 entries, corresponding to class in each dataset\n",
    "# 0 : bending (1 & 2)\n",
    "# 1 : cycling\n",
    "# 2 : lying\n",
    "# 3 : sitting\n",
    "# 4 : standing\n",
    "# 5 : walking\n",
    "# ordered as can be seen again their dataframes, corresponding to df_list which will be instantiated in similar index orders\n",
    "# thus this is a multiclass, 6 class problem, total 6 classes from 0 to 5\n",
    "\n",
    "y = pd.DataFrame(out)\n",
    "\n",
    "\n",
    "\n",
    "l = np.arange(1,21)\n",
    "datalist = np.arange(0,69)\n",
    "l_new = [1,1,2,2,3,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11,12,12,13,13,14,14,15,15,16,16,17,17,18,18,19,19,20,20]\n",
    "errors_test_estimated = pd.DataFrame(index=l, columns = ['Estimated Test Error'])\n",
    "\n",
    "\n",
    "for i in l:\n",
    "    \n",
    "    splits = np.arange(0,i)\n",
    "    segment = math.floor(480/i)\n",
    "    df_list_new = []\n",
    "    j = 0\n",
    "    for j in datalist:\n",
    "        list_df_specific = []\n",
    "        df_parts = 0\n",
    "        for df_parts in splits:\n",
    "             list_df_specific.append(df_list[j].iloc[((df_parts)*(segment)) : ((df_parts + 1)*(segment)),:].reset_index(drop=True))\n",
    "        df_list_new.append(pd.concat(list_df_specific, axis=1))\n",
    "    \n",
    "    header_column = np.arange(0, 18*i) \n",
    "    features = pd.DataFrame(index=datalist,columns=header_column) \n",
    "   \n",
    "\n",
    "    \n",
    "\n",
    "    t=0\n",
    "    for t in datalist:\n",
    "        features.iloc[t, 0 : (6*i)]       =    (((pd.DataFrame(df_list_new[t].mean()).transpose()).to_numpy()).flatten())[:]\n",
    "        features.iloc[t, (6*i) : (12*i)]  =    (((pd.DataFrame(df_list_new[t].std()).transpose()).to_numpy()).flatten())[:]\n",
    "        features.iloc[t, (12*i) : (18*i)] =    (((pd.DataFrame(df_list_new[t].max()).transpose()).to_numpy()).flatten())[:]\n",
    "    \n",
    "    \n",
    "    total = features.copy()\n",
    "    total['Output'] = out\n",
    "    \n",
    "    # note this out will stay same, irrespective of split, as each spit in each dataset in markedly instantiated against\n",
    "    # its corresponding out\n",
    "    # thus no matter the split index row 0 will have instantiated dataset df1 of bending 1 which against it will contain its\n",
    "    # class 0, also in corresponding index row 0\n",
    "    # and so on and so forth for all the corresponding classes in general\n",
    "    \n",
    "    # total has split features with output class, this is only the training data\n",
    "    \n",
    "    # total has the relevant split data that has to be cross validated upon\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5,shuffle=True)  # performing 5-fold CV \n",
    "    \n",
    "    X_train = total.drop(columns=['Output'])\n",
    "    y_train = total['Output']                   \n",
    "    \n",
    "    \n",
    "    # the errors will be saved in the error_test_estimate vector\n",
    "    # here external cv is stratified, as it wasn't used before we'll use it here\n",
    "    # additionally internal cv is automatically stratified by sklearn\n",
    "    \n",
    "    cv_error = np.zeros(5) #to store cv errors\n",
    "    \n",
    "    \n",
    "    count_ext = 0\n",
    "    for train_index, test_index in skf.split(X_train, y_train):\n",
    "        X_train_cv,X_test_cv = X_train.iloc[train_index,:],X_train.iloc[test_index,:]\n",
    "        y_train_cv,y_test_cv = y_train.iloc[train_index],y_train.iloc[test_index]\n",
    "        count_ext = count_ext + 1\n",
    "        cls =  GaussianNB().fit(X_train_cv, y_train_cv)\n",
    "        \n",
    "        y_test_cv_predicted = cls.predict(X_test_cv)\n",
    "        \n",
    "        mis = 0\n",
    "        h=0\n",
    "        for h in np.arange(0,y_test_cv.shape[0]):\n",
    "            if y_test_cv_predicted[h] != y_test_cv.iloc[h]:\n",
    "                mis = mis + 1\n",
    "        \n",
    "        error = (mis/(y_test_cv.shape[0]))*100\n",
    "        \n",
    "        cv_error[count_ext-1]=error\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "   \n",
    "   \n",
    "    error_l = np.mean(cv_error)\n",
    "    errors_test_estimated.iloc[i-1,0]=error_l\n",
    "    \n",
    "    \n",
    "    \n",
    "print('The test error estimates : \\n',errors_test_estimated)\n",
    "\n",
    "\n",
    "index = np.argmin(errors_test_estimated)\n",
    "l_selected = index + 1\n",
    "print('The l split selected that minimizes the test error estimate for this multiclass classification is : \\n',l_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here l = 4 is obtained as the optimal value\n",
    "The errors estimated in Gaussian NB is overall less than Logistic Regression for each l-value overall\n",
    "Same Runtime deliberations\n",
    "Everything else same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1        2         3        4         5        6  \\\n",
      "0   43.6297  0.374333  23.0812    0.4055  35.9903  0.417417  44.4847   \n",
      "1    43.995  0.508083  22.9187   0.66475   36.624  0.694667  42.5628   \n",
      "2     40.91  0.630833  19.2681   1.18267  29.1189  0.416417  42.3324   \n",
      "3   44.9326    0.0965  18.0383   1.23108  24.5035  0.867667  43.3015   \n",
      "4   42.7988   0.38375  15.6987  0.922917  23.5925  0.546667  44.1737   \n",
      "..      ...       ...      ...       ...      ...       ...      ...   \n",
      "64  33.6746   4.41625  15.2761   3.17008  16.1709   3.34617  32.9944   \n",
      "65  34.2582   4.95842  15.5493    3.2425  15.5917   3.56242  33.8152   \n",
      "66  34.1231   4.55242  15.6157   3.13925  16.1763   3.40575  33.9447   \n",
      "67  34.7921   4.45958  15.4255   3.19117  15.8029   3.36783  35.0495   \n",
      "68  35.5168   4.41908  15.1268     3.246     15.7   3.30275  34.3167   \n",
      "\n",
      "           7        8         9  ...    63     64    65     66     67     68  \\\n",
      "0    0.38775  23.1124  0.581417  ...  4.44  38.25   1.5   47.4      1  29.75   \n",
      "1     0.8385  23.3638  0.951333  ...   4.5   38.5   1.5  45.25   2.86  29.25   \n",
      "2   0.615333  18.8948    1.0475  ...  1.92     36   1.5   42.5   1.12     24   \n",
      "3   0.403583    17.45   1.01492  ...  4.24     26   1.5  44.25   1.58  23.25   \n",
      "4   0.373583  17.0958     0.403  ...   2.5   25.5  1.92     48   1.25     22   \n",
      "..       ...      ...       ...  ...   ...    ...   ...    ...    ...    ...   \n",
      "64   4.39992  15.6146   3.37275  ...     9  23.33  8.32  45.33  14.67  23.25   \n",
      "65   4.59817  14.8049   3.54567  ...  7.04  23.25  7.85  43.75  10.95  22.25   \n",
      "66   4.59683  15.0651   2.91158  ...   7.4  21.33  8.22     46  12.28     21   \n",
      "67   3.89633  15.6063   3.27908  ...   9.9  22.67  9.51     44  11.02  22.67   \n",
      "68   4.10558  15.5437   3.24958  ...  8.38  23.25  7.32  43.33  10.16  22.75   \n",
      "\n",
      "      69     70    71 Output  \n",
      "0   2.05  37.67   1.5      0  \n",
      "1   5.15  38.25  2.18      0  \n",
      "2   2.35   30.5     1      0  \n",
      "3   5.21     25  4.06      0  \n",
      "4   3.56     26  2.96      0  \n",
      "..   ...    ...   ...    ...  \n",
      "64  6.72     23  6.83      5  \n",
      "65  7.46   21.5  9.67      5  \n",
      "66  8.22     21  8.64      5  \n",
      "67     7   23.5  7.18      5  \n",
      "68  7.65  21.75  8.26      5  \n",
      "\n",
      "[69 rows x 73 columns]\n"
     ]
    }
   ],
   "source": [
    "i=4       # train split into 4\n",
    "    \n",
    "splits = np.arange(0,i)\n",
    "segment = math.floor(480/i)\n",
    "df_list_new = []\n",
    "j = 0\n",
    "for j in datalist:\n",
    "    list_df_specific = []\n",
    "    df_parts = 0\n",
    "    for df_parts in splits:\n",
    "         list_df_specific.append(df_list[j].iloc[((df_parts)*(segment)) : ((df_parts + 1)*(segment)),:].reset_index(drop=True))\n",
    "    df_list_new.append(pd.concat(list_df_specific, axis=1))\n",
    "\n",
    "header_column = np.arange(0, 18*i) \n",
    "features = pd.DataFrame(index=datalist,columns=header_column) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "t=0\n",
    "for t in datalist:\n",
    "    features.iloc[t, 0 : (6*i)]       =    (((pd.DataFrame(df_list_new[t].mean()).transpose()).to_numpy()).flatten())[:]\n",
    "    features.iloc[t, (6*i) : (12*i)]  =    (((pd.DataFrame(df_list_new[t].std()).transpose()).to_numpy()).flatten())[:]\n",
    "    features.iloc[t, (12*i) : (18*i)] =    (((pd.DataFrame(df_list_new[t].max()).transpose()).to_numpy()).flatten())[:]\n",
    "    \n",
    "total = features.copy()\n",
    "total['Output'] = out\n",
    "\n",
    "print(total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0         1        2         3        4         5        6   \\\n",
      "0   43.6297  0.374333  23.0812    0.4055  35.9903  0.417417  44.4847   \n",
      "1    43.995  0.508083  22.9187   0.66475   36.624  0.694667  42.5628   \n",
      "2     40.91  0.630833  19.2681   1.18267  29.1189  0.416417  42.3324   \n",
      "3   44.9326    0.0965  18.0383   1.23108  24.5035  0.867667  43.3015   \n",
      "4   42.7988   0.38375  15.6987  0.922917  23.5925  0.546667  44.1737   \n",
      "..      ...       ...      ...       ...      ...       ...      ...   \n",
      "64  33.6746   4.41625  15.2761   3.17008  16.1709   3.34617  32.9944   \n",
      "65  34.2582   4.95842  15.5493    3.2425  15.5917   3.56242  33.8152   \n",
      "66  34.1231   4.55242  15.6157   3.13925  16.1763   3.40575  33.9447   \n",
      "67  34.7921   4.45958  15.4255   3.19117  15.8029   3.36783  35.0495   \n",
      "68  35.5168   4.41908  15.1268     3.246     15.7   3.30275  34.3167   \n",
      "\n",
      "          7        8         9   ...     62    63     64    65     66     67  \\\n",
      "0    0.38775  23.1124  0.581417  ...   27.5  4.44  38.25   1.5   47.4      1   \n",
      "1     0.8385  23.3638  0.951333  ...  27.33   4.5   38.5   1.5  45.25   2.86   \n",
      "2   0.615333  18.8948    1.0475  ...     24  1.92     36   1.5   42.5   1.12   \n",
      "3   0.403583    17.45   1.01492  ...     21  4.24     26   1.5  44.25   1.58   \n",
      "4   0.373583  17.0958     0.403  ...     24   2.5   25.5  1.92     48   1.25   \n",
      "..       ...      ...       ...  ...    ...   ...    ...   ...    ...    ...   \n",
      "64   4.39992  15.6146   3.37275  ...     22     9  23.33  8.32  45.33  14.67   \n",
      "65   4.59817  14.8049   3.54567  ...     22  7.04  23.25  7.85  43.75  10.95   \n",
      "66   4.59683  15.0651   2.91158  ...   22.5   7.4  21.33  8.22     46  12.28   \n",
      "67   3.89633  15.6063   3.27908  ...  23.25   9.9  22.67  9.51     44  11.02   \n",
      "68   4.10558  15.5437   3.24958  ...     21  8.38  23.25  7.32  43.33  10.16   \n",
      "\n",
      "       68    69     70    71  \n",
      "0   29.75  2.05  37.67   1.5  \n",
      "1   29.25  5.15  38.25  2.18  \n",
      "2      24  2.35   30.5     1  \n",
      "3   23.25  5.21     25  4.06  \n",
      "4      22  3.56     26  2.96  \n",
      "..    ...   ...    ...   ...  \n",
      "64  23.25  6.72     23  6.83  \n",
      "65  22.25  7.46   21.5  9.67  \n",
      "66     21  8.22     21  8.64  \n",
      "67  22.67     7   23.5  7.18  \n",
      "68  22.75  7.65  21.75  8.26  \n",
      "\n",
      "[69 rows x 72 columns]\n",
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "     ..\n",
      "64    5\n",
      "65    5\n",
      "66    5\n",
      "67    5\n",
      "68    5\n",
      "Name: Output, Length: 69, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train = total.drop(columns = ['Output'])\n",
    "y_train = total['Output']\n",
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1        2         3        4         5        6  \\\n",
      "0   41.2855  0.320917  17.5639   0.67125  33.7482  0.588333  40.6084   \n",
      "1   43.1499    0.5245  19.7957   1.00058  33.2674  0.407583  42.1367   \n",
      "2   21.9568   1.01842  19.3943  0.683833  26.1326  0.522917  27.3939   \n",
      "3   28.6568     0.176  19.9809  0.709833    16.78     0.927  29.4863   \n",
      "4   36.9235     2.296  16.9535   3.20908  19.2545   2.95358  36.9849   \n",
      "5   37.4582   2.14425  15.8965   3.26317  18.4657     2.971  37.7263   \n",
      "6   37.8715   1.97025  16.3889   2.87283  19.9695   2.42667  37.6098   \n",
      "7   28.0153  0.239083  6.63342  0.988667  9.17217  0.649583  26.7215   \n",
      "8     32.72  0.385583  6.98633   1.11658    8.942   1.04233  48.0021   \n",
      "9        48         0  5.69625  0.277917  3.31658  0.674833  48.0021   \n",
      "10  41.9779  0.225833  15.7654  0.712417   10.002   1.25508  43.3847   \n",
      "11  46.2429  0.248083  12.9475     0.915  16.8126  0.883333    45.38   \n",
      "12  45.7532  0.428167  13.7505   1.17958  18.5665   1.12467  45.0665   \n",
      "13  46.1736     0.432  11.9219  0.997417   17.946  0.981667  46.0822   \n",
      "14  42.8172  0.544083  14.6645  0.517333  14.7217  0.769083  43.2694   \n",
      "15  44.5319  0.400083  13.5047   0.67125  16.3967  0.807083  44.3622   \n",
      "16  34.5812   3.99608  15.9131   3.10192   16.379     3.601  34.0884   \n",
      "17  34.0067     4.638  15.8421   3.27233  16.2647    3.4845  33.5192   \n",
      "18  33.4403   4.65333  15.7215   2.99667  16.2478   3.29975  33.7429   \n",
      "\n",
      "             7        8         9  ...    63     64    65     66     67  \\\n",
      "0     0.430417  17.7812     0.506  ...  5.34  38.25  1.92     45    1.3   \n",
      "1       0.1855  20.9437  0.286667  ...  5.76   38.5  3.11  45.67   1.12   \n",
      "2     0.530583  17.9028  0.547083  ...  5.19  26.75  4.97   27.5   0.94   \n",
      "3     0.286417  18.8743   0.44225  ...  4.24     25  6.76  42.75   7.76   \n",
      "4      2.48933  17.2896   2.78108  ...  7.83   24.5  8.18  44.67   7.25   \n",
      "5        2.079  16.5049   3.08083  ...  8.32     24  9.62     44   9.91   \n",
      "6      2.32408  16.5552   2.88608  ...  7.15  23.75  8.55   43.5  14.17   \n",
      "7        0.377  7.72758  0.788417  ...  3.42  11.75  2.55     30   1.25   \n",
      "8   0.00358333   6.8305  0.307917  ...   3.2     10  3.77     48      0   \n",
      "9   0.00358333  6.38167    0.6165  ...  2.05     12   1.3  48.25   0.43   \n",
      "10    0.505917  19.2034  0.509917  ...  1.87   21.5  2.59     48   4.44   \n",
      "11     0.16025  15.7876    0.6385  ...  2.68     22  2.35  46.67      1   \n",
      "12   0.0933333  14.3421   1.08308  ...     4     22  2.29  45.25   0.43   \n",
      "13    0.417083  10.4564   1.06258  ...  4.32  18.25  3.77     45    1.3   \n",
      "14     0.45725    12.21  0.756333  ...  6.56  21.25  4.64     45   1.12   \n",
      "15    0.420833  15.3176   0.48375  ...  5.85  21.25  5.73     47   3.34   \n",
      "16     3.95383   15.926   3.36725  ...  7.63     26  8.58  42.33   9.68   \n",
      "17     4.16367  15.2668   3.46783  ...     9  24.25  8.96  43.25  12.85   \n",
      "18     4.49275  15.2406   3.27967  ...  8.58   24.5  7.82     46   12.5   \n",
      "\n",
      "       68    69     70    71 Output  \n",
      "0    29.5   5.5  37.75  1.87      0  \n",
      "1   26.75  5.72  36.67   1.5      0  \n",
      "2      24  6.76  23.75  4.56      0  \n",
      "3      35  4.76     33  6.68      0  \n",
      "4      23  7.26     24  9.34      1  \n",
      "5   24.67  7.69  24.33  8.83      1  \n",
      "6      24  9.74  21.33   8.5      1  \n",
      "7      13  5.02     17   3.3      2  \n",
      "8     9.5  0.94    4.5   1.5      2  \n",
      "9    9.75  2.12     12   1.3      2  \n",
      "10   22.5  5.36     28  5.85      3  \n",
      "11  22.25  4.58  21.67  7.22      3  \n",
      "12  20.75  6.36     22  3.49      3  \n",
      "13  18.25  4.76  18.25  3.27      4  \n",
      "14     18     3  19.25  1.87      4  \n",
      "15     21  4.44     21  3.77      4  \n",
      "16   23.5  8.86  25.25  8.86      5  \n",
      "17  22.25   7.4     24  8.75      5  \n",
      "18     21  7.22     24  8.26      5  \n",
      "\n",
      "[19 rows x 73 columns]\n"
     ]
    }
   ],
   "source": [
    "df_n_1 = pd.read_csv('bending1\\\\test\\\\dataset1.csv')\n",
    "df_n_2 = pd.read_csv('bending1\\\\test\\\\dataset2.csv')\n",
    "\n",
    "df_n_3 = pd.read_csv('bending2\\\\test\\\\dataset1.csv')\n",
    "df_n_4= pd.read_csv('bending2\\\\test\\\\dataset2.csv')\n",
    "\n",
    "df_n_5 = pd.read_csv('cycling\\\\test\\\\dataset1.csv')\n",
    "df_n_6 = pd.read_csv('cycling\\\\test\\\\dataset2.csv')\n",
    "df_n_7 = pd.read_csv('cycling\\\\test\\\\dataset3.csv')\n",
    "\n",
    "df_n_8 = pd.read_csv('lying\\\\test\\\\dataset1.csv')\n",
    "df_n_9 = pd.read_csv('lying\\\\test\\\\dataset2.csv')\n",
    "df_n_10 = pd.read_csv('lying\\\\test\\\\dataset3.csv')\n",
    "\n",
    "df_n_11 = pd.read_csv('sitting\\\\test\\\\dataset1.csv')\n",
    "df_n_12 = pd.read_csv('sitting\\\\test\\\\dataset2.csv')\n",
    "df_n_13 = pd.read_csv('sitting\\\\test\\\\dataset3.csv')\n",
    "\n",
    "df_n_14 = pd.read_csv('standing\\\\test\\\\dataset1.csv')\n",
    "df_n_15 = pd.read_csv('standing\\\\test\\\\dataset2.csv')\n",
    "df_n_16 = pd.read_csv('standing\\\\test\\\\dataset3.csv')\n",
    "\n",
    "df_n_17 = pd.read_csv('walking\\\\test\\\\dataset1.csv')\n",
    "df_n_18 = pd.read_csv('walking\\\\test\\\\dataset2.csv')\n",
    "df_n_19 = pd.read_csv('walking\\\\test\\\\dataset3.csv')\n",
    "\n",
    "df_n_1 = df_n_1.drop(df_n_1.columns[0],axis=1)\n",
    "df_n_2 = df_n_2.drop(df_n_2.columns[0],axis=1)\n",
    "df_n_3 = df_n_3.drop(df_n_3.columns[0],axis=1)\n",
    "df_n_4 = df_n_4.drop(df_n_4.columns[0],axis=1)\n",
    "df_n_5 = df_n_5.drop(df_n_5.columns[0],axis=1)\n",
    "df_n_6 = df_n_6.drop(df_n_6.columns[0],axis=1)\n",
    "df_n_7 = df_n_7.drop(df_n_7.columns[0],axis=1)\n",
    "df_n_8 = df_n_8.drop(df_n_8.columns[0],axis=1)\n",
    "df_n_9 = df_n_9.drop(df_n_9.columns[0],axis=1)\n",
    "df_n_10 = df_n_10.drop(df_n_10.columns[0],axis=1)\n",
    "df_n_11 = df_n_11.drop(df_n_11.columns[0],axis=1)\n",
    "df_n_12 = df_n_12.drop(df_n_12.columns[0],axis=1)\n",
    "df_n_13 = df_n_13.drop(df_n_13.columns[0],axis=1)\n",
    "df_n_14 = df_n_14.drop(df_n_14.columns[0],axis=1)\n",
    "df_n_15 = df_n_15.drop(df_n_15.columns[0],axis=1)\n",
    "df_n_16 = df_n_16.drop(df_n_16.columns[0],axis=1)\n",
    "df_n_17 = df_n_17.drop(df_n_17.columns[0],axis=1)\n",
    "df_n_18 = df_n_18.drop(df_n_18.columns[0],axis=1)\n",
    "df_n_19 = df_n_19.drop(df_n_19.columns[0],axis=1)\n",
    "\n",
    "df_list_test = [df_n_1,df_n_2,df_n_3,df_n_4,df_n_5,df_n_6,df_n_7,df_n_8,df_n_9,df_n_10,df_n_11,df_n_12,df_n_13,df_n_14,df_n_15,df_n_16,df_n_17,df_n_18,df_n_19]\n",
    "\n",
    "out_test =     [0,      0,      0,     0,     1,     1,     1,     2,     2,     2,     3,        3,      3,     4,      4,     4,       5,      5,       5]\n",
    "\n",
    "y_test = pd.DataFrame(out_test)\n",
    "\n",
    "datalist_test = np.arange(0,19)\n",
    "\n",
    "\n",
    "\n",
    "i=4       # test split into 4\n",
    "    \n",
    "splits = np.arange(0,i)\n",
    "segment = math.floor(480/i)\n",
    "df_list_new = []\n",
    "j = 0\n",
    "for j in datalist_test:\n",
    "    list_df_specific = []\n",
    "    df_parts = 0\n",
    "    for df_parts in splits:\n",
    "         list_df_specific.append(df_list_test[j].iloc[((df_parts)*(segment)) : ((df_parts + 1)*(segment)),:].reset_index(drop=True))\n",
    "    df_list_new.append(pd.concat(list_df_specific, axis=1))\n",
    "\n",
    "header_column = np.arange(0, 18*i) \n",
    "features_test = pd.DataFrame(index=datalist_test,columns=header_column) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "t=0\n",
    "for t in datalist_test:\n",
    "    features_test.iloc[t, 0 : (6*i)]       =    (((pd.DataFrame(df_list_new[t].mean()).transpose()).to_numpy()).flatten())[:]\n",
    "    features_test.iloc[t, (6*i) : (12*i)]  =    (((pd.DataFrame(df_list_new[t].std()).transpose()).to_numpy()).flatten())[:]\n",
    "    features_test.iloc[t, (12*i) : (18*i)] =    (((pd.DataFrame(df_list_new[t].max()).transpose()).to_numpy()).flatten())[:]\n",
    "    \n",
    "total_test = features_test.copy()\n",
    "total_test['Output'] = out_test\n",
    "\n",
    "print(total_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0         1        2         3        4         5        6   \\\n",
      "0   41.2855  0.320917  17.5639   0.67125  33.7482  0.588333  40.6084   \n",
      "1   43.1499    0.5245  19.7957   1.00058  33.2674  0.407583  42.1367   \n",
      "2   21.9568   1.01842  19.3943  0.683833  26.1326  0.522917  27.3939   \n",
      "3   28.6568     0.176  19.9809  0.709833    16.78     0.927  29.4863   \n",
      "4   36.9235     2.296  16.9535   3.20908  19.2545   2.95358  36.9849   \n",
      "5   37.4582   2.14425  15.8965   3.26317  18.4657     2.971  37.7263   \n",
      "6   37.8715   1.97025  16.3889   2.87283  19.9695   2.42667  37.6098   \n",
      "7   28.0153  0.239083  6.63342  0.988667  9.17217  0.649583  26.7215   \n",
      "8     32.72  0.385583  6.98633   1.11658    8.942   1.04233  48.0021   \n",
      "9        48         0  5.69625  0.277917  3.31658  0.674833  48.0021   \n",
      "10  41.9779  0.225833  15.7654  0.712417   10.002   1.25508  43.3847   \n",
      "11  46.2429  0.248083  12.9475     0.915  16.8126  0.883333    45.38   \n",
      "12  45.7532  0.428167  13.7505   1.17958  18.5665   1.12467  45.0665   \n",
      "13  46.1736     0.432  11.9219  0.997417   17.946  0.981667  46.0822   \n",
      "14  42.8172  0.544083  14.6645  0.517333  14.7217  0.769083  43.2694   \n",
      "15  44.5319  0.400083  13.5047   0.67125  16.3967  0.807083  44.3622   \n",
      "16  34.5812   3.99608  15.9131   3.10192   16.379     3.601  34.0884   \n",
      "17  34.0067     4.638  15.8421   3.27233  16.2647    3.4845  33.5192   \n",
      "18  33.4403   4.65333  15.7215   2.99667  16.2478   3.29975  33.7429   \n",
      "\n",
      "            7        8         9   ...     62    63     64    65     66  \\\n",
      "0     0.430417  17.7812     0.506  ...  27.25  5.34  38.25  1.92     45   \n",
      "1       0.1855  20.9437  0.286667  ...   29.5  5.76   38.5  3.11  45.67   \n",
      "2     0.530583  17.9028  0.547083  ...     24  5.19  26.75  4.97   27.5   \n",
      "3     0.286417  18.8743   0.44225  ...  30.75  4.24     25  6.76  42.75   \n",
      "4      2.48933  17.2896   2.78108  ...     23  7.83   24.5  8.18  44.67   \n",
      "5        2.079  16.5049   3.08083  ...     24  8.32     24  9.62     44   \n",
      "6      2.32408  16.5552   2.88608  ...  22.75  7.15  23.75  8.55   43.5   \n",
      "7        0.377  7.72758  0.788417  ...     11  3.42  11.75  2.55     30   \n",
      "8   0.00358333   6.8305  0.307917  ...     11   3.2     10  3.77     48   \n",
      "9   0.00358333  6.38167    0.6165  ...   7.25  2.05     12   1.3  48.25   \n",
      "10    0.505917  19.2034  0.509917  ...   22.5  1.87   21.5  2.59     48   \n",
      "11     0.16025  15.7876    0.6385  ...   21.5  2.68     22  2.35  46.67   \n",
      "12   0.0933333  14.3421   1.08308  ...   20.5     4     22  2.29  45.25   \n",
      "13    0.417083  10.4564   1.06258  ...  17.33  4.32  18.25  3.77     45   \n",
      "14     0.45725    12.21  0.756333  ...  20.67  6.56  21.25  4.64     45   \n",
      "15    0.420833  15.3176   0.48375  ...  20.67  5.85  21.25  5.73     47   \n",
      "16     3.95383   15.926   3.36725  ...  21.67  7.63     26  8.58  42.33   \n",
      "17     4.16367  15.2668   3.46783  ...  23.75     9  24.25  8.96  43.25   \n",
      "18     4.49275  15.2406   3.27967  ...  25.25  8.58   24.5  7.82     46   \n",
      "\n",
      "       67     68    69     70    71  \n",
      "0     1.3   29.5   5.5  37.75  1.87  \n",
      "1    1.12  26.75  5.72  36.67   1.5  \n",
      "2    0.94     24  6.76  23.75  4.56  \n",
      "3    7.76     35  4.76     33  6.68  \n",
      "4    7.25     23  7.26     24  9.34  \n",
      "5    9.91  24.67  7.69  24.33  8.83  \n",
      "6   14.17     24  9.74  21.33   8.5  \n",
      "7    1.25     13  5.02     17   3.3  \n",
      "8       0    9.5  0.94    4.5   1.5  \n",
      "9    0.43   9.75  2.12     12   1.3  \n",
      "10   4.44   22.5  5.36     28  5.85  \n",
      "11      1  22.25  4.58  21.67  7.22  \n",
      "12   0.43  20.75  6.36     22  3.49  \n",
      "13    1.3  18.25  4.76  18.25  3.27  \n",
      "14   1.12     18     3  19.25  1.87  \n",
      "15   3.34     21  4.44     21  3.77  \n",
      "16   9.68   23.5  8.86  25.25  8.86  \n",
      "17  12.85  22.25   7.4     24  8.75  \n",
      "18   12.5     21  7.22     24  8.26  \n",
      "\n",
      "[19 rows x 72 columns]\n",
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     1\n",
      "5     1\n",
      "6     1\n",
      "7     2\n",
      "8     2\n",
      "9     2\n",
      "10    3\n",
      "11    3\n",
      "12    3\n",
      "13    4\n",
      "14    4\n",
      "15    4\n",
      "16    5\n",
      "17    5\n",
      "18    5\n",
      "Name: Output, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_test = total_test.drop(columns=['Output'])\n",
    "y_test = total_test['Output']\n",
    "print(X_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     1\n",
      "5     1\n",
      "6     1\n",
      "7     2\n",
      "8     2\n",
      "9     2\n",
      "10    3\n",
      "11    3\n",
      "12    3\n",
      "13    4\n",
      "14    4\n",
      "15    4\n",
      "16    5\n",
      "17    5\n",
      "18    5\n",
      "Name: Output, dtype: int64\n",
      "[0 0 0 0 1 1 1 2 2 2 4 3 3 3 4 4 5 5 5]\n"
     ]
    }
   ],
   "source": [
    "cls_new = GaussianNB().fit(X_train, y_train)\n",
    "y_test_predicted = cls_new.predict(X_test)    \n",
    "print(y_test)\n",
    "print(y_test_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The actual test error is : \n",
      " 10.526315789473683 %\n"
     ]
    }
   ],
   "source": [
    "wrng = 0\n",
    "for q in np.arange(0,y_test.shape[0]):\n",
    "    if y_test_predicted[q] != y_test.iloc[q]:\n",
    "        wrng = wrng + 1\n",
    "\n",
    "wrngper = (wrng/(y_test.shape[0]))*100\n",
    "print('The actual test error is : \\n',wrngper,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again the actual test error for Gaussian NB is much lesser than for Logistic Regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
