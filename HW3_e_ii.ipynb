{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HW3\n",
    "e\n",
    "ii\n",
    "\n",
    "NOTE : The error vector for 3_e_i is in percentages while for 3_d_iii was in per unit\n",
    "\n",
    "Errors : L1 penalization gives lower overall errors than final fit versions of RFE p-value elimination (see NOTE, for 3_d_iii error vector not in percentage but in per unit)\n",
    "No. of features : L1 penalization gives more features than p-value based recursive elimination. The optimal features for l=2 in L1 penalization is around 8-9, while for p-value is 2\n",
    "Again, this makes p-value RFE more interpretable but less accurate, while L1 penalization is less interpretable but overall has more accuracy\n",
    "Again this hints to the no free lunch theorem in machine learning\n",
    "\n",
    "Thus if we want more interpretable model we should go with RFE on p-value, if we want a more accurate model we should go with L1-penalization.\n",
    "\n",
    "Obviously as CV for L1 was done internally, for me, L1 penalization was much much easier and simpler to implement than was p-value based RFE\n",
    "\n",
    "I would, for the purpose of accuracy, decent enough interpretability and ease of implementation, probably go with L1-penalization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
